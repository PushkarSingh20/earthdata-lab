# -*- coding: utf-8 -*-
"""harmony.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L4Vn0ivsYODS1PDmFm3M3ZQykWt2Lt5v
"""

!pip install cartopy harmony-py matplotlib numpy xarray earthaccess

# Load packages into current runtime
import datetime as dt
import getpass

import numpy as np
import xarray as xr
import cartopy.crs as ccrs
import cartopy.feature as cfeature
import matplotlib.pyplot as plt
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
from xarray.plot.utils import label_from_attrs

from harmony import BBox, Client, Collection, Request
from harmony.config import Environment

print("Please provide your Earthdata Login credentials to allow data access")
print("Your credentials will only be passed to Earthdata and will not be exposed in the notebook")
username = input("Username:")

harmony_client = Client(env=Environment.PROD, auth=(username, getpass.getpass()))

# "Nitrogen Dioxide total column"
request = Request(
    collection=Collection(id="C3685668637-LARC_CLOUD"),
    temporal=dict(start=dt.datetime(2025, 8, 19, 0, 0, 0), stop=dt.datetime(2025, 9, 20, 23, 59, 59)),
    # Using datetime objects for temporal range
)

print(request.error_messages()) # Print error messages to diagnose
request.is_valid()

job_id = harmony_client.submit(request)
print(f"jobID = {job_id}")


harmony_client.wait_for_processing(job_id, show_progress=True)

results = harmony_client.download_all(job_id, directory="/tmp")
all_results_stored = [f.result() for f in results]

print(f"Number of result files: {len(all_results_stored)}")

datatree = xr.open_datatree(all_results_stored[0])

datatree

product_variable_name = "/product/vertical_column_stratosphere"
da = datatree[product_variable_name]
da.head()

# Print a single value from the DataArray (first time, first latitude, first longitude)
print("\nSingle value from the DataArray:")
print(da.values)

import xarray as xr
import pandas as pd
import glob

# Path to your TEMPO files
file_list = glob.glob("/tmp/*.nc4")

if file_list:
    data_arrays = []
    for file in file_list:
        try:
            dtree = xr.open_datatree(file)
            # Access the desired DataArray from the datatree
            da = dtree['/product/vertical_column_troposphere']
            data_arrays.append(da)
        except Exception as e_individual:
            print(f"Error processing individual file {file}: {e_individual}")

    if data_arrays:
        # Concatenate the data arrays along the time dimension
        combined_da = xr.concat(data_arrays, dim='time')
        print("\nCombined DataArray from individual files (Troposphere):")
        print(combined_da)
        print(f"\nNumber of NaN values in combined DataArray: {combined_da.isnull().sum().values}")
        print(f"Percentage of NaN values: {combined_da.isnull().sum().values / combined_da.size * 100:.2f}%")
        display(combined_da.isel(time=0).head().to_dataframe().reset_index())
    else:
        print("No data arrays were successfully processed from individual files.")

else:
    print("No .nc4 files found in the /tmp directory.")

# Print non-NaN values from the combined DataArray
non_nan_values = combined_da.values[~np.isnan(combined_da.values)]
print("Non-NaN values from the combined DataArray:")
print(non_nan_values)

fig, ax = plt.subplots(figsize=(10, 6), subplot_kw={"projection": data_proj})

make_nice_map(ax)

# Get the longitude and latitude from the combined_da
lon = combined_da['longitude']
lat = combined_da['latitude']

# Select a single time slice to plot (e.g., the first time step)
data_to_plot = combined_da.isel(time=0)

contour_handle = ax.contourf(
    lon,
    lat,
    data_to_plot,
    levels=100,
    vmin=0,
    vmax=1e16, # Adjust vmax based on the data range if necessary
    zorder=2,
)

cb = plt.colorbar(contour_handle)
cb.set_label(label_from_attrs(combined_da))

plt.title(f'Tropospheric NO2 vertical column at {data_to_plot.time.values}') # Add a title with the timestamp

plt.show()

data_proj = ccrs.PlateCarree()


def make_nice_map(axis):
    axis.add_feature(cfeature.STATES, color="gray", lw=0.1)
    axis.coastlines(resolution="50m", color="gray", linewidth=0.5)

    axis.set_extent([-150, -40, 14, 65], crs=data_proj)
    grid = axis.gridlines(draw_labels=["left", "bottom"], dms=True)
    grid.xformatter = LONGITUDE_FORMATTER
    grid.yformatter = LATITUDE_FORMATTER

fig, ax = plt.subplots(figsize=(10, 6), subplot_kw={"projection": data_proj})

make_nice_map(ax)

lon, lat = np.meshgrid(datatree["geolocation/longitude"], datatree["geolocation/latitude"])

contour_handle = ax.contourf(
    lon,
    lat,
    da.where(datatree["product/cloud_pressure"] < 9.96920e+36).where(datatree["product/cloud_fraction"] >=0).squeeze(),
    levels=100,
    vmin=0,
    vmax=1,
    zorder=2,
)

cb = plt.colorbar(contour_handle)
cb.set_label(label_from_attrs(da))

plt.show()



# Select the cloud_fraction DataArray and apply the mask
cloud_fraction_da = datatree["product/cloud_fraction"].where(datatree["product/cloud_pressure"] < 9.96920e+36).squeeze()

# Calculate and print min, max, and check for NaNs
print(f"Min cloud fraction: {cloud_fraction_da.min().values}")
print(f"Max cloud fraction: {cloud_fraction_da.max().values}")
print(f"Number of NaN values: {cloud_fraction_da.isnull().sum().values}")
print(f"Total number of values: {cloud_fraction_da.size}")

fig, ax = plt.subplots(figsize=(10, 6), subplot_kw={"projection": data_proj})

make_nice_map(ax)

lon, lat = np.meshgrid(datatree["geolocation/longitude"], datatree["geolocation/latitude"])

# Select the solar_zenith_angle DataArray and apply the mask
solar_zenith_angle_da = datatree["geolocation/solar_zenith_angle"].where(datatree["product/cloud_pressure"] < 9.96920e+36).squeeze()


contour_handle = ax.contourf(
    lon,
    lat,
    solar_zenith_angle_da,
    levels=100,
    vmin=0, # Keep the original vmin for solar zenith angle
    zorder=2,
)

cb = plt.colorbar(contour_handle)
# Set the label for the solar zenith angle colorbar
cb.set_label(label_from_attrs(solar_zenith_angle_da))

plt.show()